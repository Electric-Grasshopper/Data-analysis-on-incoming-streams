{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit"
  },
  "interpreter": {
   "hash": "5d97ad4eda96f4e0dcd5ae4f97368654619500468c6147550d2a1b2a1881f9a5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Preparation\n",
    "\n",
    "### In this notebook we will prepare our data for our search function to use. <br>Currently we have data stored in four different ```csv``` files.<br>\n",
    "* movies.csv\n",
    "* links.csv\n",
    "* ratings.csv\n",
    "* tags.csv\n",
    "<br>\n",
    "### It can be computationally expensive to produce ```analysis results``` from multiple data-sources for incomming stream of requests.<br> So we will prepare our data and save it in an ```easily searchable``` structure."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed modules...\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from os import getcwd"
   ]
  },
  {
   "source": [
    "## Define Paths to data files."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_LINKS   = f\"{getcwd()}/dataStore/links.csv\"\n",
    "PATH_MOVIES  = f\"{getcwd()}/dataStore/movies.csv\"\n",
    "PATH_RATINGS = f\"{getcwd()}/dataStore/ratings.csv\"\n",
    "PATH_TAGS    = f\"{getcwd()}/dataStore/tags.csv\""
   ]
  },
  {
   "source": [
    "# Data Engineering<br>\n",
    "* ## Get data in dataframes.\n",
    "* ## Convert data to a single dictionary."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "COLUMNS : ['movieId', 'title', 'genres']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Read data from movies.csv\n",
    "\"\"\"\n",
    "df_movies            = pd.read_csv(PATH_MOVIES)\n",
    "movies_table_columns = df_movies.columns.tolist()\n",
    "print(f\"COLUMNS : {movies_table_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "COLUMNS : ['movieId', 'imdbId', 'tmdbId']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Read data from links.csv\n",
    "\"\"\"\n",
    "df_links            = pd.read_csv(PATH_LINKS)\n",
    "links_table_columns = df_links.columns.tolist()\n",
    "print(f\"COLUMNS : {links_table_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "COLUMNS : ['userId', 'movieId', 'rating', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Read data from ratings.csv\n",
    "\"\"\"\n",
    "df_ratings         = pd.read_csv(PATH_RATINGS)\n",
    "path_table_columns = df_ratings.columns.tolist()\n",
    "print(f\"COLUMNS : {path_table_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "COLUMNS : ['userId', 'movieId', 'tag', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Read data from tags.csv\n",
    "\"\"\"\n",
    "df_tags            = pd.read_csv(PATH_TAGS)\n",
    "tags_table_columns = df_tags.columns.tolist()\n",
    "print(f\"COLUMNS : {tags_table_columns}\")"
   ]
  },
  {
   "source": [
    "* ### ```movieId``` is a common column in all four tables so we will use it as a primary search-key <br>\n",
    "* ### ```userId```  is a common key across two tables, so we will use it as a sort key...\n",
    "* ### A user will always search a movie by its ```title``` so we will create a ```Global secondary index``` to be able to perform search our datastore. <br>it will obviously take some extra space but almost negligible as compared to the size of the original data. <br>In addition, It will make our searching faster and efficient so it's a good deal."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "It is True  that the column 'movieId' has unique values for all entries in movies dataframe.\nIt is True  that the column 'movieId' has unique values for all entries in links dataframe.\nIt is False that the column 'userId'  has unique values for all entries in ratings dataframe.\nIt is False that the column 'userId'  has unique values for all entries in tags dataframe.\n"
     ]
    }
   ],
   "source": [
    "print(f\"It is {pd.Series(df_movies['movieId']).is_unique}  that the column 'movieId' has unique values for all entries in movies dataframe.\")\n",
    "print(f\"It is {pd.Series(df_links['movieId']).is_unique}  that the column 'movieId' has unique values for all entries in links dataframe.\")\n",
    "print(f\"It is {pd.Series(df_ratings['userId']).is_unique} that the column 'userId'  has unique values for all entries in ratings dataframe.\")\n",
    "print(f\"It is {pd.Series(df_tags['userId']).is_unique} that the column 'userId'  has unique values for all entries in tags dataframe.\")\n",
    "\n",
    "# Sort movie dataframe on the basis of movieId as movieId is unique for all entries...\n",
    "df_movies_sorted = df_movies.sort_values(by=['movieId'])\n",
    "\n",
    "# Sort links dataframe on the basis of movieId as movieId is unique for all entries...\n",
    "df_links_sorted  = df_links.sort_values(by=['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from movies dataframe...\n",
    "movieIds    = df_movies_sorted[\"movieId\"].tolist()\n",
    "movieTitles = df_movies_sorted[\"title\"].tolist()\n",
    "movieGenres = [genre.split(\"|\") for genre in df_movies[\"genres\"].tolist()]\n",
    "\n",
    "# from links dataframe...\n",
    "imdbId  = df_links_sorted[\"imdbId\"].tolist()\n",
    "tmdbId  = df_links_sorted[\"tmdbId\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDict             = {}\n",
    "global_secondaryIndex = {}\n",
    "for idx, movieId in enumerate(movieIds):\n",
    "    movieDict[movieId] = {\n",
    "        \"genre\" : movieGenres[idx],\n",
    "        \"links\" : {\n",
    "            \"imdb\" : imdbId[idx], \n",
    "            \"tmdb\" : tmdbId[idx]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    global_secondaryIndex[movieTitles[idx]] = movieId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete veriables which are no longer in use while holding large amount of data.\n",
    "del movieIds\n",
    "del movieTitles\n",
    "del movieGenres\n",
    "del imdbId\n",
    "del tmdbId"
   ]
  },
  {
   "source": [
    "### Add all user ratings for individual movies.\n",
    "#### The goal is to group all ratings of a ```movie``` togather, so that we will be able to retrieve user ratings of a particular movie.\n",
    "#### Now, this one is a bit tricky as there is no column in the ratings dataframe which offers unique values. <br>So will have to perform grouping.\n",
    "#### We will use ```movieId``` column as it is a common column in all of our data sources and it will make it easy to add the same data in our  new ```movie``` dataset.\n",
    "\n",
    "#### The procedure defined below may be computationally gross but should be good enough for a single time execution..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all columns of ratings table into individual lists...\n",
    "userIds       = df_ratings[\"userId\"].tolist()\n",
    "movieIds      = df_ratings[\"movieId\"].tolist()\n",
    "user_ratings  = df_ratings[\"rating\"].tolist()\n",
    "timestamps    = df_ratings[\"timestamp\"].tolist()\n",
    "\n",
    "ratings = {}\n",
    "\n",
    "for idx, mid in enumerate(movieIds):\n",
    "    # Do the movieId previously exist?\n",
    "    try   : _ = ratings[mid]\n",
    "    # If not, Add it in the record...\n",
    "    except: \n",
    "        ratings[mid]   = [\n",
    "            {\n",
    "                \"userId\"     : userIds[idx],\n",
    "                \"rating\"     : user_ratings[idx],\n",
    "                \"time_stamp\" : timestamps[idx]\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    try   : _ = ratings[mid][userIds[idx]]\n",
    "    except: ratings[mid].append(\n",
    "            {\n",
    "                \"userId\"     : userIds[idx],\n",
    "                \"rating\"     : user_ratings[idx],\n",
    "                \"time_stamp\" : timestamps[idx]\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Finally, add the data in the movieDict...\n",
    "for mid, _ in movieDict.items():\n",
    "    try   : movieDict[mid][\"user_rating\"] = ratings[mid][1:]\n",
    "    except: \n",
    "        try   : movieDict[mid][\"user_rating\"] = [] # If Movie ID exists in the movie dict...\n",
    "        except: pass # If the Movie ID doesn't exist in our record..."
   ]
  },
  {
   "source": [
    "### Add all user given tags for individual movies.\n",
    "#### The goal is to group all tags given to a ```movie``` togather, so that we will be able to retrieve tags of a particular movie.\n",
    "#### This one is also tricky as there is no column in the tags dataframe which offers unique values. <br>So will have to perform grouping.\n",
    "#### We will use ```movieId``` column as it is a common column in all of our data sources and it will make it easy to add the same data in our  new ```movie``` dataset.\n",
    "\n",
    "#### The procedure defined below may also be computationally gross but should be good enough for a single time execution..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all columns of ratings table into individual lists...\n",
    "userIds    = df_tags[\"userId\"].tolist()\n",
    "movieIds   = df_tags[\"movieId\"].tolist()\n",
    "user_tag   = df_tags[\"tag\"].tolist()\n",
    "timestamps = df_tags[\"timestamp\"].tolist()\n",
    "\n",
    "tags = {}\n",
    "for idx, mid in enumerate(movieIds):\n",
    "    # Do the movieId previously exist?\n",
    "    try   : _ = tags[mid]\n",
    "    # If not, Add it in the record...\n",
    "    except: tags[mid] = [\n",
    "        {\n",
    "            \"userId\"     : userIds[idx],\n",
    "            \"rating\"     : user_tag[idx],\n",
    "            \"time_stamp\" : timestamps[idx]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try   : _ = ratings[mid][userIds[idx]]\n",
    "    except: tags[mid].append(\n",
    "            {\n",
    "                \"userId\"     : userIds[idx],\n",
    "                \"rating\"     : user_tag[idx],\n",
    "                \"time_stamp\" : timestamps[idx]\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Finally, add the data in the movieDict...\n",
    "for mid, _ in movieDict.items():\n",
    "    try   : movieDict[mid][\"tags\"] = tags[mid][1:]\n",
    "    except: \n",
    "        try   : movieDict[mid][\"tags\"] = [] # If Movie ID exists in the movie dict...\n",
    "        except: del global_secondaryIndex[mid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] Writing movie Data into the disk...\n",
      "[INFO] Writing Global Secondary Index Data into the disk...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(\"[INFO] Writing movie Data into the disk...\")\n",
    "with open('dataStore/dataFinal.json', 'w') as fp:\n",
    "    json.dump(movieDict, fp, sort_keys=True, indent=4)\n",
    "print(\"[INFO] Writing Global Secondary Index Data into the disk...\")\n",
    "with open('dataStore/dataFinal_GIS.json', 'w') as fp:\n",
    "    json.dump(global_secondaryIndex, fp, sort_keys=True, indent=4)"
   ]
  },
  {
   "source": [
    "#### At this point, our database is ready and it can handel high inflow of requests."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}